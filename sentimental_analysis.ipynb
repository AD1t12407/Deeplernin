{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "10a64e3b564e4f83bcc826387fa79393": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed4b81db5867490fa29c1cbf65818912",
              "IPY_MODEL_a3bc3c55bce54afdb07c74705c9cbc17",
              "IPY_MODEL_b5c3d5d565e1439d9ba6297da017d1cb"
            ],
            "layout": "IPY_MODEL_f35d3a379de0428e9aa12213e421ae3d"
          }
        },
        "ed4b81db5867490fa29c1cbf65818912": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50d4b05c3a794020a8c3db8a9b8d168f",
            "placeholder": "​",
            "style": "IPY_MODEL_06010a8dd6904cdbaeab21eca9c7f7eb",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "a3bc3c55bce54afdb07c74705c9cbc17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22bc63b4428a43f6a8cd0aa84e24f9d8",
            "max": 669491321,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0f2ae10d1d00440582649a9b5c07e910",
            "value": 669491321
          }
        },
        "b5c3d5d565e1439d9ba6297da017d1cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c2278cf750043f8a1975fa906cccd12",
            "placeholder": "​",
            "style": "IPY_MODEL_441eccce15f54e09aadd9470432b36f9",
            "value": " 669M/669M [00:08&lt;00:00, 92.3MB/s]"
          }
        },
        "f35d3a379de0428e9aa12213e421ae3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50d4b05c3a794020a8c3db8a9b8d168f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06010a8dd6904cdbaeab21eca9c7f7eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22bc63b4428a43f6a8cd0aa84e24f9d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f2ae10d1d00440582649a9b5c07e910": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9c2278cf750043f8a1975fa906cccd12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "441eccce15f54e09aadd9470432b36f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n"
      ],
      "metadata": {
        "id": "I2BDa2bXjSh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5NVJAUEhxdk"
      },
      "outputs": [],
      "source": [
        "\n",
        "import transformers\n",
        "from transformers import AutoTokenizer,AutoModelForSequenceClassification\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sure, here's an explanation of each import statement:\n",
        "\n",
        "1. `import transformers`: This imports the entire `transformers` library, which is a popular library for natural language processing (NLP) tasks, particularly focused on transformer-based models like BERT, GPT, and others.\n",
        "\n",
        "2. `from transformers import AutoTokenizer, AutoModelForSequenceClassification`: This imports specific classes from the `transformers` library.\n",
        "   - `AutoTokenizer` is a class that automatically selects the appropriate tokenizer for a given pre-trained model. Tokenizers are used to convert text into numerical input that can be understood by NLP models.\n",
        "   - `AutoModelForSequenceClassification` is a class that automatically selects the appropriate pre-trained model for sequence classification tasks. It typically includes models fine-tuned on large datasets for tasks like sentiment analysis, text classification, etc.\n",
        "\n",
        "3. `import requests`: This imports the `requests` library, which is commonly used for making HTTP requests in Python. It allows you to interact with web servers, making it useful for tasks like web scraping, API calls, etc.\n",
        "\n",
        "4. `from bs4 import BeautifulSoup`: This imports the `BeautifulSoup` class from the `bs4` module. BeautifulSoup is a Python library used for web scraping. It provides tools for parsing HTML and XML documents, making it easier to extract data from web pages.\n",
        "\n",
        "5. `import re`: This imports the `re` module, which provides support for regular expressions in Python. Regular expressions are powerful tools for pattern matching and string manipulation. They can be used for tasks like searching, replacing, or validating strings based on specific patterns."
      ],
      "metadata": {
        "id": "h__t-XMYi5gT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=AutoTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
        "model=AutoModelForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "10a64e3b564e4f83bcc826387fa79393",
            "ed4b81db5867490fa29c1cbf65818912",
            "a3bc3c55bce54afdb07c74705c9cbc17",
            "b5c3d5d565e1439d9ba6297da017d1cb",
            "f35d3a379de0428e9aa12213e421ae3d",
            "50d4b05c3a794020a8c3db8a9b8d168f",
            "06010a8dd6904cdbaeab21eca9c7f7eb",
            "22bc63b4428a43f6a8cd0aa84e24f9d8",
            "0f2ae10d1d00440582649a9b5c07e910",
            "9c2278cf750043f8a1975fa906cccd12",
            "441eccce15f54e09aadd9470432b36f9"
          ]
        },
        "id": "FmBX0tYCiK3a",
        "outputId": "8c1fccd8-017d-446a-b42e-1a85d4d87cdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/669M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10a64e3b564e4f83bcc826387fa79393"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1. `tokenizer=AutoTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')`:\n",
        "   - This line initializes a tokenizer using the `AutoTokenizer.from_pretrained()` method.\n",
        "   - It loads a pre-trained tokenizer from the Hugging Face model hub.\n",
        "   - The `'nlptown/bert-base-multilingual-uncased-sentiment'` string specifies the model identifier, indicating which pre-trained tokenizer to load. This particular tokenizer is trained on multilingual text data and is not case-sensitive.\n",
        "   \n",
        "2. `model=AutoModelForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')`:\n",
        "   - This line initializes a pre-trained BERT model for sequence classification using the `AutoModelForSequenceClassification.from_pretrained()` method.\n",
        "   - It also loads the model from the Hugging Face model hub.\n",
        "   - Similarly, the `'nlptown/bert-base-multilingual-uncased-sentiment'` string specifies the model identifier, indicating which pre-trained model to load. This model is specifically fine-tuned for sentiment analysis tasks on multilingual text data.\n",
        "\n",
        "After executing these lines of code, you'll have a tokenizer object (`tokenizer`) and a model object (`model`) ready to be used for sentiment analysis tasks on multilingual text data. You can then tokenize input text using the tokenizer and pass the tokenized input to the model for inference to predict the sentiment of the text."
      ],
      "metadata": {
        "id": "qbuy-a9ck8z3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens=tokenizer.encode('it was good but could have been better. Great',return_tensors='pt')\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYWwiVsDk_VV",
        "outputId": "d3f8eead-9391-449a-d106-6dfba973b656"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  101, 10197, 10140, 12050, 10502, 12296, 10574, 10662, 16197,   119,\n",
              "         11838,   102]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tokens=tokenizer.encode('it was good but could have been better. Great',return_tensors='pt'):\n",
        "tokenizer.encode() is a method provided by the tokenizer object (tokenizer). It converts the input text into a sequence of tokens suitable for input to the model.\n",
        "The input text, 'it was good but could have been better. Great', is the text you want to tokenize.\n",
        "return_tensors='pt' specifies that the output should be returned as PyTorch tensors. PyTorch is a popular deep learning framework in Python. By setting return_tensors='pt', the output tokens will be returned as PyTorch tensors.\n",
        "tokens:\n",
        "This variable holds the output of the tokenizer.encode() operation.\n",
        "It contains the tokenized representation of the input text.\n",
        "The tokens are represented as PyTorch tensors, as specified by the return_tensors='pt' argument."
      ],
      "metadata": {
        "id": "th2LRZzrnm5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result=model(tokens)\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0543IG8lWNu",
        "outputId": "549083bc-ec14-4b1e-f24f-1f5d6de479d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequenceClassifierOutput(loss=None, logits=tensor([[-2.8836, -1.3482,  1.4180,  2.0596,  0.5641]],\n",
              "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltxhRyYCl-en",
        "outputId": "cba9574e-d0da-4c8d-ea44-9322569ed320"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.8836, -1.3482,  1.4180,  2.0596,  0.5641]],\n",
              "       grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1. `result=model(tokens)`:\n",
        "   - This line of code passes the tokenized input `tokens` to the pre-trained BERT model (`model`) for inference.\n",
        "   - The `model` object represents the pre-trained BERT model for sequence classification that was initialized earlier.\n",
        "   - The `tokens` variable contains the tokenized representation of the input text.\n",
        "   - By calling `model(tokens)`, you're effectively sending the tokenized input through the BERT model for processing.\n",
        "\n",
        "2. `result`:\n",
        "   - This variable holds the output of the model's inference.\n",
        "   - After passing the tokenized input through the model, `result` likely contains the model's predictions or outputs.\n",
        "   - The specific contents of `result` depend on the architecture and configuration of the pre-trained BERT model being used.\n",
        "   - In the context of sentiment analysis, `result` might contain probabilities or scores indicating the sentiment of the input text (e.g., positive, negative, neutral).\n",
        "   - It's common to further process or interpret the contents of `result` based on the requirements of your application or task. For instance, you might extract the predicted sentiment label from the output scores or probabilities.\n",
        "\n",
        "In summary, this code segment executes inference on the pre-trained BERT model with the tokenized input and stores the model's output in the variable `result`."
      ],
      "metadata": {
        "id": "Lto3hz8envYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "int(torch.argmax(result.logits))+1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a92vx2gLmEdD",
        "outputId": "b8add7f0-b60d-46bd-b9df-6b923b6a5a8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1. `result.logits`:\n",
        "   - `result` likely represents the output of the BERT model's inference on the input text.\n",
        "   - The `.logits` attribute of `result` typically contains the raw output scores or logits produced by the model before any final activation function (e.g., softmax) is applied.\n",
        "   - In the context of sentiment analysis, these logits might represent the model's confidence scores for each sentiment class.\n",
        "\n",
        "2. `torch.argmax(result.logits)`:\n",
        "   - `torch.argmax()` is a function from the PyTorch library that returns the index of the maximum value in a tensor.\n",
        "   - Applied to `result.logits`, it returns the index of the sentiment class with the highest confidence score according to the model's output.\n",
        "   - This index corresponds to the predicted sentiment class.\n",
        "\n",
        "3. `int(torch.argmax(result.logits))+1`:\n",
        "   - `int()` is a Python built-in function that converts its argument to an integer.\n",
        "   - By wrapping `torch.argmax(result.logits)` with `int()`, you convert the index of the predicted sentiment class to an integer.\n",
        "   - `+1` is added to the result because sentiment class indices are often zero-indexed, meaning they start from 0. Adding 1 adjusts the index to start from 1, which is more intuitive for sentiment labels (e.g., 1 for negative, 2 for neutral, 3 for positive).\n",
        "\n",
        "In summary, this code segment extracts the predicted sentiment class from the model's output logits and converts it to an integer representation suitable for interpretation and further processing."
      ],
      "metadata": {
        "id": "MOMeCOJ8n7BE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r=requests.get('https://www.yelp.com/biz/social-brew-cafe-pyrmont')\n",
        "soup=BeautifulSoup(r.text,'html.parser')\n",
        "regex=re.compile('.comment.')\n",
        "results=soup.find_all('p',{'class':regex})\n",
        "reviews=[result.text for result in results]"
      ],
      "metadata": {
        "id": "1_TNpmRFoljX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1. `r=requests.get('https://www.yelp.com/biz/social-brew-cafe-pyrmont')`:\n",
        "   - This line sends an HTTP GET request to the specified URL (`'https://www.yelp.com/biz/social-brew-cafe-pyrmont'`) using the `requests.get()` function from the `requests` library.\n",
        "   - It retrieves the HTML content of the webpage located at the specified URL.\n",
        "   - The response object is stored in the variable `r`.\n",
        "\n",
        "2. `soup=BeautifulSoup(r.text,'html.parser')`:\n",
        "   - `BeautifulSoup` is a Python library used for parsing HTML and XML documents.\n",
        "   - Here, `r.text` contains the HTML content of the webpage retrieved in the previous step.\n",
        "   - By passing `r.text` and `'html.parser'` as arguments to `BeautifulSoup`, the HTML content is parsed into a BeautifulSoup object called `soup`.\n",
        "   - `soup` can then be used to navigate and manipulate the HTML structure of the webpage.\n",
        "\n",
        "3. `regex=re.compile('.comment.')`:\n",
        "   - This line compiles a regular expression pattern using the `re.compile()` function from the `re` module.\n",
        "   - The pattern `'.comment.'` is a regular expression that matches any string containing the substring `'comment'`.\n",
        "   - This regular expression will be used to find HTML elements with class names containing the substring `'comment'`.\n",
        "\n",
        "4. `results=soup.find_all('p',{'class':regex})`:\n",
        "   - `soup.find_all()` is a BeautifulSoup method that searches the parsed HTML document (`soup`) for all HTML elements that match the specified criteria.\n",
        "   - Here, it searches for all `<p>` (paragraph) elements with class names matching the regular expression pattern compiled earlier (`regex`).\n",
        "   - The matching elements are stored in the list `results`.\n",
        "\n",
        "5. `reviews=[result.text for result in results]`:\n",
        "   - This is a list comprehension that extracts the text content of each HTML element in the list `results`.\n",
        "   - For each element (`result`) in `results`, `result.text` retrieves the text content of the element.\n",
        "   - The extracted text content is stored as a list of strings in the variable `reviews`.\n",
        "   - Each string in `reviews` represents the text of a review or comment found on the webpage that matches the specified criteria.\n",
        "\n",
        "In summary, this code retrieves HTML content from a Yelp webpage, parses it using BeautifulSoup, finds all paragraphs with class names containing `'comment'`, and extracts the text of these paragraphs, effectively retrieving reviews or comments from the webpage."
      ],
      "metadata": {
        "id": "ry7eoIpPqHFU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SAJk_yoNqLIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oSaoSoJBnx5S"
      }
    }
  ]
}